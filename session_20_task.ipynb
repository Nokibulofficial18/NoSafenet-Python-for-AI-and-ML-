{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nokibulofficial18/NoSafenet-Python-for-AI-and-ML-/blob/main/session_20_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tWO36cIgWlev"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA DESCRIPTION\n",
        "```\n",
        "file name -> Columns\n",
        "quater-i.csv -> ['order_id', 'quantity', 'item_id', 'choice_description_id' 'item_price']\n",
        "items.csv -> ['item_id', 'item_name']\n",
        "```\n",
        "Dataset Link - https://drive.google.com/drive/folders/1Z0kaFybvgFeczeUj4dldUnhTdloLqLsL?usp=share_link"
      ],
      "metadata": {
        "id": "zMEk5SAYWqbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import like this\n",
        "items_path = \"/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/items.csv\"\n",
        "q1_path = \"/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/quarter-1.csv\"\n",
        "q2_path = \"/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/quarter-2.csv\"\n",
        "q3_path = \"/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/quarter-3.csv\"\n",
        "\n",
        "\n",
        "q1= pd.read_csv(q1_path)\n",
        "q2 = pd.read_csv(q2_path)\n",
        "q3 = pd.read_csv(q3_path)\n",
        "\n",
        "items = pd.read_csv(items_path)"
      ],
      "metadata": {
        "id": "5qxjEvSwfDkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3efe4612-3e42-4354-e08a-8acde3423d3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/quarter-1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2637193459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mq1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq2_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DSMP/01 - Python/Daily Tasks/Week 7/data/quarter-1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Qt0W4ngl0zbl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "items_path = \"https://drive.google.com/uc?id=1MokLL6WAVRrA4TcWSCocTG_U7H-iN4Nw\"\n",
        "q1_path = \"https://drive.google.com/uc?id=17Tca-FYOu-qMpAaJBUuC2E1Ex3jCMpFg\"\n",
        "q2_path = \"https://drive.google.com/uc?id=1pIBukQRAJi5ksNR5lNj0qslIbrlS_Bzf\"\n",
        "q3_path = \"https://drive.google.com/uc?id=19d3AsHDuTj5ZiH-HthdfLmEBWF4T-Oyd\"\n",
        "\n",
        "items = pd.read_csv(items_path)\n",
        "q1 = pd.read_csv(q1_path)\n",
        "q2 = pd.read_csv(q2_path)\n",
        "q3 = pd.read_csv(q3_path)\n"
      ],
      "metadata": {
        "id": "Serf4_9-1EGU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q3.head()"
      ],
      "metadata": {
        "id": "ymUrKgiP2kA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`Q:1-5`\n",
        "1. You are given three quater files, your job is to append these three files and make a single dataframe.\n",
        "2. Have a index as Q-1 Q-2 Q-3 for respective quater files in the dataframe\n",
        "3. Your are given a file items.csv which has item_id and item_name. Find out most sold items in each quarter.\n",
        "4. Find out items which has made most revenue in each quarter.\n",
        "5. Find out avg order price of each quarter.\n",
        "\n",
        "***Note: item_price is given as str with $ sign, in earlier task you have converted this to rupees, here too first convert item_price field in rupees.***"
      ],
      "metadata": {
        "id": "zEhub0BcW1Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here\n",
        "full_month = pd.concat([pd.concat([q1,q2]),q3])\n"
      ],
      "metadata": {
        "id": "nwICqy-RWyEf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1_top = items.merge(q1, how=\"inner\", on=\"item_id\") \\\n",
        "              .groupby('item_id')['quantity'].count() \\\n",
        "              .sort_values(ascending=False).head(1)\n",
        "\n",
        "q1_id = q1_top.index[0]\n",
        "q1_top = items[items['item_id'] == q1_id]\n",
        "name = q1_top['item_name'].values[0]\n",
        "\n",
        "print(f\"Highest sell item in quarter 1 is: {name}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WkOIf6kV3mHC",
        "outputId": "956e3b81-85b6-4d1f-cd64-7752cbc1a794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest sell item in quarter 1 is: Chicken Bowl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q2_top = items.merge(q2, how=\"inner\", on=\"item_id\") \\\n",
        "              .groupby('item_id')['quantity'].count() \\\n",
        "              .sort_values(ascending=False).head(1)\n",
        "\n",
        "q2_id = q2_top.index[0]\n",
        "q2_top = items[items['item_id'] == q2_id]\n",
        "name = q2_top['item_name'].values[0]\n",
        "\n",
        "print(f\"Highest sell item in quarter 2 is: {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt20wT7vRzrm",
        "outputId": "7268879e-666b-4b12-edcf-4604c715345c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest sell item in quarter 2 is: Chicken Bowl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# q3_top = items.merge(q3, how=\"inner\", on=\"item_id\") \\\n",
        "#               .groupby('item_id')['quantity'].count() \\\n",
        "#               .sort_values(ascending=False).head(1)\n",
        "\n",
        "# q3_id = q3_top.index[0]\n",
        "# q3_top = items[items['item_id'] == q3_id]\n",
        "# name = q3_top['item_name'].values[0]\n",
        "\n",
        "# print(f\"Highest sell item in quarter 3 is: {name}\")\n"
      ],
      "metadata": {
        "id": "y0gtOBUiSCyG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_month['item_price'] = full_month['item_price'].str.replace('$','',regex=False).astype(float)\n",
        "top_rev = items.merge(full_month, how=\"inner\", on=\"item_id\") \\\n",
        "              .groupby('item_id')['item_price'].sum() \\\n",
        "              .sort_values(ascending=False).head(1)\n",
        "top_rev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "uO6p7oJrYzfr",
        "outputId": "5427199a-b00c-442f-ed0d-fa525a688df3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "item_id\n",
              "4    7342.73\n",
              "Name: item_price, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7342.73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_compute_avg(q_df, quarter_name):\n",
        "    # Step 1: Clean item_price column (remove $ and convert to float)\n",
        "    q_df = q_df.copy()\n",
        "    q_df['item_price'] = q_df['item_price'].str.replace('$', '', regex=False).astype(float)\n",
        "    # q_df['item_price'] *= 110  # Convert USD to BDT if required\n",
        "\n",
        "    # Step 2: Compute revenue per row\n",
        "    q_df['revenue'] = q_df['item_price'] * q_df['quantity']\n",
        "\n",
        "    # Step 3: Compute total revenue per order\n",
        "    order_totals = q_df.groupby('order_id')['revenue'].sum()\n",
        "\n",
        "    # Step 4: Compute average order price\n",
        "    avg_order_price = order_totals.mean()\n",
        "\n",
        "    print(f\"Average order price in {quarter_name}: ${avg_order_price:.2f}\")\n",
        "    return avg_order_price\n",
        "\n",
        "# Apply the function to each quarter\n",
        "avg_q1 = clean_and_compute_avg(q1, \"Q1\")\n",
        "avg_q2 = clean_and_compute_avg(q2, \"Q2\")\n",
        "avg_q3 = clean_and_compute_avg(q3, \"Q3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGvTXTjTaGTM",
        "outputId": "279386a6-3d5d-426c-b856-14383dea2c74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average order price in Q1: $13.81\n",
            "Average order price in Q2: $13.28\n",
            "Average order price in Q3: $nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`Q-6` From the IPL wala dataset you have to find the Purple cap holder each season.\n",
        "\n",
        "*Note: Bowler with most no wickets in a season gets purple cap. If more than one bowler have same no of wickets in the season, one with least ecomnomy among them is purple cap holder.*\n",
        "\n",
        "Bowler's Economy = runs-conceded per six balls"
      ],
      "metadata": {
        "id": "IRg-rNsDW-Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NeJ0ySlSCOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoQvfRvp3la3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "yQeUfliHXKJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`Q-7:` Best bowler in death overs.\n",
        "*Note: Have taken most no of wickets in case of tie with least economy*\n",
        "\n",
        "Death Overs - [16-20]"
      ],
      "metadata": {
        "id": "pmJJB0Q6XMWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "s2t1IXf-XLak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`Q-8` Batsman record season wise\n",
        "\n",
        "Make a function which takes a input `batsman_name` and it returns a dataframe.\n",
        "Columns of the data frame are - `['Season','Innings', 'TotalRuns', 'Avg', 'HighestScore','StrikeRate']`.\n",
        "* In result make `Season` column as index.\n",
        "\n",
        "* Avg - total_runs/ no of time got out. - player_out column will help.\n",
        "* StrikeRate -(total_runs/ balls faced) * 100- wides are not included in batsman ball faced counts. No balls are included. -> Extra_type column will help\n",
        "* Batsman Can score runs on No Balls.\n",
        "* Batsman can get out on No Ball or Wides. And even while being on non-striker. Keep these things in mind before masking."
      ],
      "metadata": {
        "id": "BHU3PYRTXbPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "3RQTt5ELXdbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`Q-9` Using both dataset, make a dataframe as described below\n",
        "\n",
        "Data Frame columns-> `['PlayerOfThematch', 'BattingFigure', 'BowlingFigure']`\n",
        "\n",
        "* BattingFigure->`<runs>/<balls>`\n",
        "* BowlingFigure->`<wicket>/<runs-conceded>`\n",
        "\n",
        "DataFrame should have one record for each match.\n",
        "\n",
        "Say 'V Kohli' got POM award then in dataset include his batting figure of that match. Say he scored 112runs in 76 balls. And he hasn't bowled so Bowling Figure will be NaN\n",
        "```\n",
        "PlayerOfThematch BattingFigure BowlingFigure\n",
        "V Kohli          112/76         nan  \n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "jMyy5LcUXjUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "uh36R6AZXn82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Questions Based on Iris Dataset**\n",
        "\n",
        "- **Sepal All:** https://docs.google.com/spreadsheets/d/e/2PACX-1vT58ekmHTwptX7Bs4QOy6YByA1HMvYTACeeIjrKhHE0Pg1K_3egewHMKMh02zN9D5-yHVXfvuaa3s5u/pub?gid=2028782809&single=true&output=csv\n",
        "    - **Unnamed: 0:** Unused column. This column is created when creating this sub-dataset.\n",
        "    - **Id:** Id of the records.\n",
        "    - **SepalLengthCm:** Sepal length of flowers in cm\n",
        "    - **SepalWidthCm:** Sepal width of flowers in cm\n",
        "\n",
        "- **Petal All:** https://docs.google.com/spreadsheets/d/e/2PACX-1vQinLXShrOz4ExNaW1bSQVuvbbhIzJW7G0kkkD2SvqSD6STjLrQQiftgI7BGe10sBZi0CNr2_sJpQAz/pub?gid=1580010789&single=true&output=csv\n",
        "    - **Unnamed: 0:** Unused column. This column is created when creating this sub-dataset.\n",
        "    - **Id:** Id of the records.\n",
        "    - **PetalLengthCm:** Petal length of flowers in cm\n",
        "    - **PetalWidthCm:** Petal width of flowers in cm\n",
        "\n",
        "- **Iris Virginica:** https://docs.google.com/spreadsheets/d/e/2PACX-1vSK39MwduGPHYNgw5yViezoLYCVDKMCWIHzjnt3GZNaxHPFOQLr2q6no_tyqTsOk-VfXleslfGVe9eJ/pub?gid=314231613&single=true&output=csv\n",
        "    - **Unnamed: 0:** Unused column. This column is created when creating the sub-dataset.\n",
        "    - **Id:** Id of the records.\n",
        "    - **Species:** Name of this species.\n",
        "\n",
        "- **Iris Versicolor:** https://docs.google.com/spreadsheets/d/e/2PACX-1vTcSFgLnabqIrgIc5WlwvnbbvyyJsgZjR-0E0-4TR-5aHgv_0EP6yNWglkkls3AXM2qHCR5VYzWCoTM/pub?gid=715607857&single=true&output=csv\n",
        "    - **Unnamed: 0:** Unused column. This column is created when creating the sub-dataset.\n",
        "    - **Id:** Id of the records.\n",
        "    - **Species:** Name of this species.\n",
        "\n",
        "- **Iris Setosa:** https://docs.google.com/spreadsheets/d/e/2PACX-1vSjqJpdgy2X_oDUUqQ0sSaFKqnnf8MYU4KgJSYgHaHmq0Wb1weMOsJXh-rICHmkLcaTkOwzMYLeh959/pub?gid=2003684803&single=true&output=csv\n",
        "    - **Unnamed 0:** Unused column. This column is created when creating the sub-dataset.\n",
        "    - **Id:** Id of the records.\n",
        "    - **Species:** Name of this species."
      ],
      "metadata": {
        "id": "iljGaXfzXq1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sepal_all = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT58ekmHTwptX7Bs4QOy6YByA1HMvYTACeeIjrKhHE0Pg1K_3egewHMKMh02zN9D5-yHVXfvuaa3s5u/pub?gid=2028782809&single=true&output=csv\")\n",
        "petal_all = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQinLXShrOz4ExNaW1bSQVuvbbhIzJW7G0kkkD2SvqSD6STjLrQQiftgI7BGe10sBZi0CNr2_sJpQAz/pub?gid=1580010789&single=true&output=csv\")\n",
        "\n",
        "virginica = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSK39MwduGPHYNgw5yViezoLYCVDKMCWIHzjnt3GZNaxHPFOQLr2q6no_tyqTsOk-VfXleslfGVe9eJ/pub?gid=314231613&single=true&output=csv\")\n",
        "versicolor = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTcSFgLnabqIrgIc5WlwvnbbvyyJsgZjR-0E0-4TR-5aHgv_0EP6yNWglkkls3AXM2qHCR5VYzWCoTM/pub?gid=715607857&single=true&output=csv\")\n",
        "setosa = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSjqJpdgy2X_oDUUqQ0sSaFKqnnf8MYU4KgJSYgHaHmq0Wb1weMOsJXh-rICHmkLcaTkOwzMYLeh959/pub?gid=2003684803&single=true&output=csv\")\n"
      ],
      "metadata": {
        "id": "nY1khG0XXp1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Q-9:` Plot a bar chart of the average Sepal Length  of Virginica and average Petal length of Setosa flower."
      ],
      "metadata": {
        "id": "R6jqy4GQX4RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "zTx5S3yiX15D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Q-10:` Create the complete dataset by uisng the below datasets:\n",
        "- virginica\n",
        "- versicolor\n",
        "- setosa\n",
        "- sepal all\n",
        "- petal all\n",
        "\n",
        "This dataset should have these below column names in order:\n",
        "1. Id\n",
        "2. Species\n",
        "3. SepalLengthCm\n",
        "4. SepalWidthCm\n",
        "5. PetalLengthCm\n",
        "6. PetalWidthCm\n",
        "\n",
        "Also, the dataset should be shuffled means the `Id` column should not be in increasing or decreasing order. So, make a dataset which has the shuffled Id column. You can use `DataFrame.sample()` method to shuffle."
      ],
      "metadata": {
        "id": "ecWHo_gsYAT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "PsWBn7g3YDRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Q-11:` Find out the maximum and minimum sepal width and petal width of Setosa and Versicolor. To do this:\n",
        "- First create a dataset with merging the required datasets\n",
        "- After that, use `groupby` to create groups based on the \"Species\" column.\n",
        "- Then find out which are asked in this question.\n",
        "\n",
        "\n",
        "The output should be like this:\n",
        "```bash\n",
        "Minimum Sepal width of Setosa is 2.3\n",
        "Maximum Sepal width of Setosa is 4.4\n",
        "\n",
        "**************************************************\n",
        "\n",
        "Minimum Sepal width of Versicolor is 2.0\n",
        "Maximum Sepal width of Versicolor is 3.4\n",
        "\n",
        "**************************************************\n",
        "```"
      ],
      "metadata": {
        "id": "FLlBdChyYHtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "T7toJgSkYIIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}